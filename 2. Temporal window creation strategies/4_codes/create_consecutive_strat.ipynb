{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmoup7_Xsbc4"
   },
   "source": [
    "# Ego4D create enhanced NLQ dataset for pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBsjg8pN0knX"
   },
   "source": [
    "## Download Data and Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcNVEU5Z8f5p"
   },
   "source": [
    "### **Fill In Your Access Info Here**\n",
    "If you don't have access and secret keys, first sign the Ego4D License at [ego4ddataset.com](https://ego4ddataset.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lTSvhBsBvnXy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = \"\"\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcIg7gNx82Bq"
   },
   "source": [
    "### **Set up CLIs and Download Annotations + Repo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-D9Jm-l162m",
    "outputId": "c51130b2-0769-442f-f1ce-32274057d46d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 57.9M  100 57.9M    0     0   140M      0 --:--:-- --:--:-- --:--:--  141M\n"
     ]
    }
   ],
   "source": [
    "# Download the AWS and Ego4D CLIs, then download the annotations locally\n",
    "# Set up the AWS CLI\n",
    "!curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "!unzip -o awscliv2.zip >/dev/null\n",
    "!sudo ./aws/install >/dev/null 2>&1\n",
    "!aws configure set aws_access_key_id \"$AWS_ACCESS_KEY_ID\" && aws configure set aws_secret_access_key \"$AWS_SECRET_ACCESS_KEY\"\n",
    "!rm \"awscliv2.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tXEDSW50Ebd"
   },
   "source": [
    "### Install the ego4d CLI and Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Jg6Xt1p-On-a",
    "outputId": "e7663e49-f7be-4f63-9e22-03157cbd52b4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting ego4d\n",
      "  Downloading ego4d-1.7.3.tar.gz (94 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/94.5 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m \u001B[32m92.2/94.5 kB\u001B[0m \u001B[31m2.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m94.5/94.5 kB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting boto3 (from ego4d)\n",
      "  Downloading boto3-1.34.144-py3-none-any.whl (139 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m139.2/139.2 kB\u001B[0m \u001B[31m5.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ego4d) (4.66.4)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from ego4d) (2024.5.15)\n",
      "Collecting dataclasses-json (from ego4d)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting iopath (from ego4d)\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.2/42.2 kB\u001B[0m \u001B[31m3.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting botocore<1.35.0,>=1.34.144 (from boto3->ego4d)\n",
      "  Downloading botocore-1.34.144-py3-none-any.whl (12.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.4/12.4 MB\u001B[0m \u001B[31m34.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->ego4d)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->ego4d)\n",
      "  Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m82.7/82.7 kB\u001B[0m \u001B[31m11.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->ego4d)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.2/49.2 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json->ego4d)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath->ego4d) (4.12.2)\n",
      "Collecting portalocker (from iopath->ego4d)\n",
      "  Downloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.144->boto3->ego4d) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.144->boto3->ego4d) (2.0.7)\n",
      "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->ego4d) (24.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json->ego4d)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.144->boto3->ego4d) (1.16.0)\n",
      "Building wheels for collected packages: ego4d, iopath\n",
      "  Building wheel for ego4d (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for ego4d: filename=ego4d-1.7.3-py3-none-any.whl size=118250 sha256=8dcf40d85e7f181e0f6324d12d50d9605f7ee4fbb11783c1b779d921718b5a63\n",
      "  Stored in directory: /root/.cache/pip/wheels/65/a8/89/a6187e3bc9a85e81899ab8d5ddc2011c9954d3b6cb84d47e03\n",
      "  Building wheel for iopath (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=121c4babc7d7ebc8b958a53248dec1875a00eec8e3132e73e52237f487516be4\n",
      "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
      "Successfully built ego4d iopath\n",
      "Installing collected packages: portalocker, mypy-extensions, marshmallow, jmespath, typing-inspect, iopath, botocore, s3transfer, dataclasses-json, boto3, ego4d\n",
      "Successfully installed boto3-1.34.144 botocore-1.34.144 dataclasses-json-0.6.7 ego4d-1.7.3 iopath-0.1.10 jmespath-1.0.1 marshmallow-3.21.3 mypy-extensions-1.0.0 portalocker-2.10.0 s3transfer-0.10.2 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "# Set up the Ego4D CLI\n",
    "!pip install ego4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tcKr9i88KMaa",
    "outputId": "b4d4b72a-5bf3-4ace-ad64-f49a4eb123c8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Datasets to download: {'annotations'}\n",
      "Download Path: /content/ego4d_data/v1\n",
      "Downloading Ego4D metadata json..\n",
      "Ego4D Metadata: /content/ego4d_data/ego4d.json\n",
      "Checking requested datasets and versions...\n",
      "Created download directory for version 'v1' of dataset: 'annotations' at: /content/ego4d_data/v1/annotations\n",
      "Benchmarks specified but ignored without a benchmarks field in manifest.\n",
      "Retrieving object metadata from S3...\n",
      "100% 31/31 [00:00<00:00, 793.93object/s]\n",
      "Checking if latest file versions are already downloaded...\n",
      "  0% 0/31 [00:00<?, ?file/s]WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: ego4d-consortium-sharing.s3.us-west-1.amazonaws.com. Connection pool size: 10\n",
      " 32% 10/31 [00:00<00:00, 39.30file/s]WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: ego4d-consortium-sharing.s3.us-west-1.amazonaws.com. Connection pool size: 10\n",
      "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: ego4d-consortium-sharing.s3.us-west-1.amazonaws.com. Connection pool size: 10\n",
      "100% 31/31 [00:00<00:00, 105.04file/s]\n",
      "No existing videos to filter.\n",
      "Downloading 31 files..\n",
      " 99% 2.49G/2.51G [00:24<00:00, 204MiB/s]Checking file integrity...\n",
      "100% 2.51G/2.51G [00:24<00:00, 108MiB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download the Ego4D Annotations to ego4d_data/\n",
    "!ego4d --output_directory=\"/content/ego4d_data/\" --datasets annotations --benchmarks nlq -y --version v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Flbksi8eMBtK"
   },
   "source": [
    "Load the json files in pyton dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "IfgwIsuOBIhM"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "metadata = json.load(open(\"/content/ego4d_data/ego4d.json\"))\n",
    "narration = json.load(open(\"/content/ego4d_data/v1/annotations/narration.json\"))\n",
    "nlq_val = json.load(open(\"/content/ego4d_data/v1/annotations/nlq_val.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Open a file in write mode\n",
    "with open(\"UIDs_of_visual_features.txt\", \"w\") as file:\n",
    "    for item in features_list:\n",
    "        file.write(f\"{item}\\n\")\n",
    "\n",
    "print(\"List saved\")"
   ],
   "metadata": {
    "id": "YcBIBtnHvyHz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Open the file in read mode\n",
    "with open(\"UIDs_of_visual_features.txt\", \"r\") as file:\n",
    "    vis_features_from_txt = [line.strip() for line in file]\n",
    "\n",
    "print(vis_features_from_txt[0:12])"
   ],
   "metadata": {
    "id": "6L6NGkVbw8hy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ccca2c37-09a6-400f-83e4-f7e9cb9525e0"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['d66f42bb-822b-444a-bce0-ddd15b29bd1b', '._e091d046-ebbf-456e-a56d-5aa743c88202', '._46f82b66-39e2-46e1-beee-229848800b1b', '._bd8fd228-ec64-4515-b7ab-af261c0a5807', '2e1f40e1-169e-488c-bd9b-9c47cfee31ab', '._80535887-f8d0-4b40-aef3-47a3912b0bcb', 'da8b599a-c7a4-45aa-9a4c-a12af1c6926a', '._459503f6-d3b1-4641-843c-63bf1644e6da', '._1f2e985f-ea94-4ec4-bc22-f5516e693d7d', '892a25e2-df0c-4577-af57-b720e73654f6', '._a1cf9215-730c-4c5a-9980-3108250984c2', '._6e8d8309-821a-4b0a-8e3f-6cd74f59cb44']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "features_list = vis_features_from_txt"
   ],
   "metadata": {
    "id": "yt-9WyONJgcR"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "ETtBhkaJVoOu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RakRb4IpBy0J"
   },
   "outputs": [],
   "source": [
    "videos = metadata.get(\"videos\")\n",
    "clips = metadata.get(\"clips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rBhEdtqPsdi"
   },
   "source": [
    "Skip the videos that are included in nlq_train and nlq_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aA-BTE0XPrZP",
    "outputId": "fe8d4194-6af8-4258-a41c-74fb287e1525"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of nlq_val_videos_ids:  247\n"
     ]
    }
   ],
   "source": [
    "nlq_val_videos = nlq_val.get(\"videos\")\n",
    "nlq_val_videos_ids= []\n",
    "for item in nlq_val_videos:\n",
    "  nlq_val_videos_ids.append(item[\"video_uid\"])\n",
    "\n",
    "print(\"Number of nlq_val_videos_ids: \",len(nlq_val_videos_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmS9go79R8bq",
    "outputId": "86f2ddc8-c537-424e-e6a6-22620895b07f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of nlq_train_videos_ids: 754\n"
     ]
    }
   ],
   "source": [
    "nlq_train = json.load(open(\"/content/ego4d_data/v1/annotations/nlq_train.json\"))\n",
    "\n",
    "nlq_train_videos = nlq_train.get(\"videos\")\n",
    "nlq_train_videos_ids= []\n",
    "for item in nlq_train_videos:\n",
    "  nlq_train_videos_ids.append(item[\"video_uid\"])\n",
    "\n",
    "print(\"Number of nlq_train_videos_ids:\", len(nlq_train_videos_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7VHqet7tPrbu",
    "outputId": "e5cc33eb-b16c-4a00-f3f8-e848dd57081f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12283\n"
     ]
    }
   ],
   "source": [
    "metadata_clips = metadata.get(\"clips\")\n",
    "metadata_clips_video_ids = []\n",
    "for item in metadata_clips:\n",
    "  metadata_clips_video_ids.append(item[\"video_uid\"])\n",
    "\n",
    "# of videos included in metadata\n",
    "print(len(metadata_clips_video_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# In the above code there is duplicates. only unique videos needed\n"
   ],
   "metadata": {
    "id": "Wvi1hoURaWuV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "unique_video_ids = list(set(metadata_clips_video_ids))\n",
    "\n",
    "# Print the number of unique video IDs,\n",
    "# means only 3878 video has clips\n",
    "print(\"number of videos with clips:\", len(unique_video_ids))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sFo2aa5caPIZ",
    "outputId": "bc4d440f-809f-4a18-e71b-947207c0a0c5"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "number of videos with clips: 3878\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVvC6jPkUN74",
    "outputId": "651a92b5-8a4b-4485-8604-d3c8b6209bde"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9645\n"
     ]
    }
   ],
   "source": [
    "narration_videos = list(narration.keys())\n",
    "print(len(narration_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJUTZwUAPret",
    "outputId": "aeab997e-9c06-4478-f0bc-b1ee03fba418"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "allowed_videos: 8891\n"
     ]
    }
   ],
   "source": [
    "excluded_videos = nlq_train_videos_ids + nlq_val_videos\n",
    "\n",
    "allowed_videos = [item for item in narration_videos if item not in excluded_videos]\n",
    "print(\"allowed_videos:\", len(allowed_videos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zzRW15gVMWs"
   },
   "source": [
    "So far, we used only narration.json. Now, we will combine the informations from the metadata and narrations to create real json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa2Buy61EpBt",
    "outputId": "8d201a24-5c82-4d75-e0e9-088b86e00584"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of common files: 8839\n"
     ]
    }
   ],
   "source": [
    "# Convert the lists to sets\n",
    "set1 = set(features_list)\n",
    "set2 = set(allowed_videos)\n",
    "\n",
    "# Find the intersection of the two sets\n",
    "common_files = set1.intersection(set2)\n",
    "\n",
    "# Get the count of the common files\n",
    "common_files_count = len(common_files)\n",
    "\n",
    "# Print the count\n",
    "print(\"Number of common files:\", common_files_count)\n",
    "\n",
    "common_files = list(common_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creation of main dataset\n",
    "\n",
    "* This script processes video metadata and narration data to build a dictionary of videos, each containing clips and their corresponding annotations, while applying filters on the number of narrations and clips.\n"
   ],
   "metadata": {
    "id": "nxgeFO55TfyK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_narrations_for_current_clip(video_start_sec, video_end_sec, narrations_dict):\n",
    "  \"\"\"\n",
    "  This method takes as input the start_sec, the end_sec of the clip and\n",
    "  all narrations from narration.json that correspond to the video.\n",
    "\n",
    "  The method outputs a filtered narrations_dict containing only the narrations inside the video\n",
    "\n",
    "  I do it this way because later is very easy to change the logic of the strategy\n",
    "  when we already have only the narrations from the current list\n",
    "  \"\"\"\n",
    "\n",
    "  LENGTH = len(narrations_dict)\n",
    "\n",
    "\n",
    "  result_list = []\n",
    "\n",
    "  i = 0\n",
    "\n",
    "  # We iterate through the narrations until we find the first narration for the clip\n",
    "  while LENGTH> i+1 and narrations_dict[i]['timestamp_sec']< video_start_sec:\n",
    "    i = i + 1\n",
    "\n",
    "  start_index = i\n",
    "\n",
    "  #We iterate through the remaining part, create and add dictionaries to the list\n",
    "  #until we find the last narration that is fully inside the clip\n",
    "  while LENGTH> i+1 and narrations_dict[i+1]['timestamp_sec']< video_end_sec:\n",
    "    i = i + 1\n",
    "\n",
    "  end_index = i\n",
    "\n",
    "  return narrations_dict[start_index:end_index+1]"
   ],
   "metadata": {
    "id": "YyDbKGu-m928"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_language_queries(narrs, pos, num_of_narrs, start_sec):\n",
    "  language_narrations = []\n",
    "\n",
    "  if pos+num_of_narrs >= len(narrs):\n",
    "    print(pos)\n",
    "    print(num_of_narrs)\n",
    "    print(len(narrs))\n",
    "\n",
    "  narrs_start_sec = narrs[pos][\"timestamp_sec\"] - start_sec\n",
    "  narrs_end_sec = narrs[pos+num_of_narrs +1][\"timestamp_sec\"] - start_sec\n",
    "\n",
    "  for narr in narrs[position: position + num_of_narrs]:\n",
    "    language_narrations.append({\n",
    "            \"clip_start_sec\" : narrs_start_sec ,\n",
    "            \"clip_end_sec\" : narrs_end_sec,\n",
    "            \"query\": narr[\"narration_text\"]\n",
    "        })\n",
    "\n",
    "  return language_narrations"
   ],
   "metadata": {
    "id": "zuHG8U63kHz3"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "we will get the narrations from here and then we apply the random stuff, and selection of the narrations, directly from the narrations for the current video"
   ],
   "metadata": {
    "id": "UcDTeqJcqFME"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "random.seed(12)"
   ],
   "metadata": {
    "id": "gbYQanflVkXt"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# all videos 1 clip 8-12 consecutive narrs"
   ],
   "metadata": {
    "id": "T1r_dMq3xdhy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Set parameters\n",
    "min_narr_per_clip = 11  # min number of narrations per clip\n",
    "max_narr_per_clip = 14 # man number of narrations per clip\n",
    "filter_max_clips = 1   # max used number of clips per video\n",
    "\n",
    "\n",
    "metadata_clips_as_dict = metadata.get(\"clips\")\n",
    "big_dictionary = {\"videos\":[]}\n",
    "videos_counter = 0\n",
    "skipped_videos = 0\n",
    "\n",
    "for video_uid in narration:\n",
    "  # Skip videos not in common_files\n",
    "  if video_uid not in common_files:\n",
    "    skipped_videos = skipped_videos+1\n",
    "    continue\n",
    "\n",
    "  # get clips for this video\n",
    "  metadata_clips = [item for item in metadata_clips_as_dict if item.get(\"video_uid\") == video_uid]\n",
    "  if len(metadata_clips) == 0:\n",
    "    continue\n",
    "\n",
    "  list_of_clips = []\n",
    "  # here we filter out how many clips we are going to use, starting from the first clip\n",
    "  for clip in metadata_clips[0:filter_max_clips]:\n",
    "    dic_with_metadata = {\n",
    "        \"clip_uid\" : clip[\"clip_uid\"],\n",
    "        \"video_start_sec\" : clip[\"video_start_sec\"],\n",
    "        \"video_end_sec\" : clip[\"video_end_sec\"],\n",
    "        \"annotations\":[]\n",
    "    }\n",
    "\n",
    "    video = narration[video_uid]\n",
    "    if not video:\n",
    "      continue\n",
    "    narrator_1 = video.get(\"narration_pass_1\")\n",
    "    if not narrator_1:\n",
    "      continue\n",
    "\n",
    "    narrations_for_vid = (narrator_1.get(\"narrations\"))\n",
    "    if len(narrations_for_vid) < 1:\n",
    "      continue\n",
    "\n",
    "    # Generate a random number corresponding to the count of narrations for the current clip, for example 12\n",
    "    number_of_narrations = random.randint(min_narr_per_clip, max_narr_per_clip)\n",
    "\n",
    "    # Get all narrations for the current clip in the correct format\n",
    "    narrations_for_clip = get_narrations_for_current_clip(clip[\"video_start_sec\"], clip[\"video_end_sec\"], narrations_for_vid)\n",
    "\n",
    "    if len(narrations_for_clip) <= number_of_narrations +2:\n",
    "      continue\n",
    "\n",
    "    position = random.randint(0, len(narrations_for_clip) - number_of_narrations - 2)\n",
    "\n",
    "    language_queries = get_language_queries(narrations_for_clip, position, number_of_narrations, clip[\"video_start_sec\"])\n",
    "\n",
    "    if len(language_queries) < 1:\n",
    "      continue\n",
    "\n",
    "    annotation_uid = narrations_for_vid[0][\"annotation_uid\"]\n",
    "    dic_with_metadata[\"annotations\"].append({\n",
    "        \"language_queries\":language_queries,\n",
    "        \"annotation_uid\":annotation_uid\n",
    "        })\n",
    "\n",
    "\n",
    "    list_of_clips.append(dic_with_metadata)\n",
    "\n",
    "  # Append video to final dictionary if it has valid clips\n",
    "  if len(list_of_clips) != 0:\n",
    "    ids_dictionary = {\n",
    "        \"video_uid\" : video_uid,\n",
    "        \"clips\": list_of_clips\n",
    "    }\n",
    "    big_dictionary[\"videos\"].append(ids_dictionary)\n",
    "  videos_counter = videos_counter + 1\n",
    "\n",
    "print(\"Total number of videos:\", videos_counter)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7SH1GJ8ad0RB",
    "outputId": "0f79a740-31a8-4f4d-8d16-f6bd94b3aa96"
   },
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of videos: 3123\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "random.shuffle(big_dictionary[\"videos\"])"
   ],
   "metadata": {
    "id": "0DzU69SypJOx"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check if everything is correct"
   ],
   "metadata": {
    "id": "ulVOhX6_WKzW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "number_of_queries_per_video = []\n",
    "number_of_queries_per_clip = []\n",
    "number_of_queries_per_annotation = []\n",
    "anns = []\n",
    "total_number_of_queries = 0\n",
    "\n",
    "for vid in big_dictionary[\"videos\"]:\n",
    "\n",
    "    number_of_queries_v = 0\n",
    "    for clip in vid[\"clips\"]:\n",
    "\n",
    "        number_of_queries_c = 0\n",
    "        for ann in clip[\"annotations\"]:\n",
    "\n",
    "            num_of_q_ann = 0\n",
    "            for query in ann[\"language_queries\"]:\n",
    "                total_number_of_queries = total_number_of_queries + 1\n",
    "                num_of_q_ann = num_of_q_ann +1\n",
    "                number_of_queries_c = number_of_queries_c +1\n",
    "                number_of_queries_v = number_of_queries_v +1\n",
    "            number_of_queries_per_annotation.append(num_of_q_ann)\n",
    "        number_of_queries_per_clip.append(number_of_queries_c)\n",
    "    number_of_queries_per_video.append(number_of_queries_v)\n",
    "\n",
    "print(\"Total number of queries:\", total_number_of_queries)\n",
    "print(\"number of clips with 0 language queries\", number_of_queries_per_clip.count(0))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WfYCg7JtWDdX",
    "outputId": "7d8dcf33-21fe-4082-edc1-29ceae32005d"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of queries: 26040\n",
      "number of clips with 0 language queries 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving the dataset"
   ],
   "metadata": {
    "id": "bY75f8eKWEdy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "6lDzytYG1TvJ"
   },
   "outputs": [],
   "source": [
    "# Save the modified dictionary back to the JSON file\n",
    "with open('consecutive.json', 'w') as file:\n",
    "    json.dump(big_dictionary, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "consecutive_merged = {\"videos\": big_dictionary[\"videos\"] + nlq_train[\"videos\"]}\n",
    "random.shuffle(consecutive_merged[\"videos\"])"
   ],
   "metadata": {
    "id": "bByDzqCrK0eW"
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Save the modified dictionary back to the JSON file\n",
    "with open('consecutive_merged.json', 'w') as file:\n",
    "    json.dump(consecutive_merged, file, indent=4)"
   ],
   "metadata": {
    "id": "CkMosLV_M4Jl"
   },
   "execution_count": 27,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
